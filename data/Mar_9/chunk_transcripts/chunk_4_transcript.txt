==== Beginning of Part 4 ====
[0:30:00]use our jobs and then it's going to be a very scary scenario.
[0:30:02]So we came up with this kind of assumptions
[0:30:05]that the combinations of AI and humans
[0:30:08]are always better than humans or always better than AI.
[0:30:11]We see that, I mean, these kind of very general hypothesis,
[0:30:15]these do not necessarily hold when we deep dive
[0:30:18]into different tasks and when we look at tasks
[0:30:21]that are completely different from one another.
[0:30:24]So I think that we are in a specific period of time
[0:30:28]that we are just removing whatever assumptions
[0:30:30]that we had already so that we clean the space
[0:30:33]for new assumptions, for more valid assumptions to grow
[0:30:36]that will probably come out of newer studies
[0:30:39]like the ones that we just saw,
[0:30:41]or the minds of scientists that you just quoted from.
[0:30:44]So I think that we are in a very turbulent period of time
[0:30:50]with respect to incorporating AI into our daily practices,
[0:30:54]most importantly medicine, because it's a very sensitive
[0:30:57]and very critical aspect of practice.
[0:31:00]I think a lot of things are going to change
[0:31:01]as we go forward and we cannot really stick
[0:31:05]to those general statements like,
[0:31:08]yes, AI is going to replace doctors
[0:31:11]or doctors who know AI are going to replace doctors
[0:31:13]who don't know.
[0:31:14]These things are very, very general, very vague.
[0:31:17]They do not necessarily hold that much of value
[0:31:19]at the moment.
[0:31:19]We should just wait and see what comes.
[0:31:21]And probably the only thing that we can do at the moment
[0:31:24]is to just keep ourselves ready to be able to adapt
[0:31:29]to whatever changes that come in the future
[0:31:31]as soon as possible.
[0:31:32]That is the most important thing that we can do now.
[0:31:35]Yeah, and I think similar to this situation that we are in
[0:31:39]has been experienced in probably in the first years
[0:31:44]of this century with the advent of internet
[0:31:47]and everyone was probably guessing in the wrong ways
[0:31:50]about internet in the first days
[0:31:52]that like no one is going to use internet
[0:31:55]who is going to pay for this
[0:31:57]and who's going to connect their computer to this internet.
[0:32:00]And I'm sure you've seen those titles or headlines
[0:32:05]from the newspapers, the widely known newspapers
[0:32:09]saying that this internet is going to fail.
[0:32:11]And at some point, many companies at the dot-com bubble,
[0:32:16]many companies went down because people got disappointed
[0:32:21]the internet advent for some time.
[0:32:23]So what I want to say is that the course
[0:32:27]of these new technologies and new ages of technology
[0:32:32]that basically are highly difficult to predict.
[0:32:37]And as you mentioned, the only thing that is kind of
[0:32:40]like logical to do is to just be educated enough
[0:32:47]to adapt to whatever happens
[0:32:49]and be fast to jump on the train,
[0:32:52]whatever trains that comes out of the tunnel
[0:32:54]and be able to adapt your skills
[0:32:57]to whatever that is taking shape.
[0:33:01]And I think many of these sayings like,
[0:33:04]no AI is not taking your job,
[0:33:06]only some people with AI are going to replace you
[0:33:09]or something like this are just heartwarming sentences
[0:33:12]that we tell ourselves in order to avoid
[0:33:15]some probable trauma that is going to happen.
[0:33:18]I'm not thinking about it in a way that,
[0:33:22]okay, it is the end of the time
[0:33:24]and we are going to be useless.
[0:33:25]I'm sure that there are going to be lots of cooler
[0:33:29]and more interesting jobs to do
[0:33:30]than just to type things down about patients
[0:33:34]and take histories of patients.
[0:33:36]Probably our intelligence and AI intelligence
[0:33:40]are going to be used in different places
[0:33:42]and in the most efficient way.
[0:33:44]We are just going to find how.
[0:33:47]Yes, there is going to be lots of job loss and everything,
[0:33:51]but like always, I think there will be some sorts
[0:33:56]of new jobs that will be created.
[0:33:58]Maybe this time there's less jobs created for humans
[0:34:02]and most of the things that are intelligence-based
[0:34:05]are going to be occupied by AI,
[0:34:08]but still I think that wouldn't be a very bad scenario
[0:34:12]because people could spend more time on creative adventures
[0:34:17]and they won't be held without any work to do or something.
[0:34:22]But I want to know your view about this dystopian
[0:34:27]and utopian views of the end of the world scenarios
[0:34:31]and what you think about it
[0:34:34]or whether you think about it or not
[0:34:36]and you just want to adapt to the current situation
[0:34:40]and see what happens.
[0:34:43]I mean, to be honest with you,
[0:34:44]I don't know what is coming up.
[0:34:47]And I think that very, I mean,
[0:34:50]many different industries are currently
[0:34:52]in an uncertain condition, uncertain situation.
[0:34:57]It's not only about medicine,
[0:34:58]it's about many, many different industries as well.
[0:35:00]I mean, I believe the forefront of these changes,
[0:35:04]whatever changes that you're talking about
[0:35:06]is going to be software engineering, right?
[0:35:07]You know, this software engineers,
[0:35:09]whoever who has been spent years on that trail
[0:35:12]now might feel like even more frustrated
[0:35:14]than whoever doctor can feel like
[0:35:16]because they're seeing exactly what Cursor 3.7
[0:35:19]can do, for example, and you know.
[0:35:21]They will be the first to be replaced
[0:35:22]if anyone's going to be replaced
[0:35:23]because software engineers themselves
[0:35:26]are the most adept to whatever is happening in the field
[0:35:28]and they will invent products to replace themselves
[0:35:34]much sooner than the other fields, I think.
[0:35:36]Yet, you know, if you look at them,
[0:35:38]you still see a lot of amazing people
[0:35:40]who are creating these new AIs,
[0:35:42]who are basically using these new AIs
[0:35:44]to solving new problems.
[0:35:45]So I would say that if, you know,
[0:35:48]of whatever scenario, whatever one-liner scenario
[0:35:51]that comes to our mind, that this is going to happen,
[0:35:53]that is going to happen.
[0:35:55]I mean, the fact that you can describe a scenario
[0:35:57]in one sentence probably means that
[0:36:00]that scenario is not true because, you know,
[0:36:02]I would say that the worst thing you can do
[0:36:06]is to come up with simplified explanations
[0:36:08]for very complicated and complex phenomena.
[0:36:10]This is not the way that the world operates.
[0:36:13]And if you just go back to history,
[0:36:15]you see that most of these predictions like that
[0:36:18]about the future has not been true.
[0:36:20]So you just need to do a retrospective cohort
[0:36:22]to see how many of these predictions
[0:36:24]and modeling that people made actually came true.
[0:36:27]How many times did we predict that AI
[0:36:29]is going to extinct humans and it didn't?
[0:36:32]How many times we predicted that internet
[0:36:34]is going to replace something else
[0:36:36]and it didn't?
[0:36:37]One of them that I clearly remember was, for example,
[0:36:39]regarding the future of education
[0:36:41]once the online learning came into existence
[0:36:44]and people thought that, you know,
[0:36:45]online learning is going to replace in-person learning
[0:36:48]where we know that this didn't happen.
[0:36:50]And in fact, something came into existence
[0:36:53]like blended learning,
[0:36:54]which was the combination of the two.
[0:36:55]And then some courses are now better taught
[0:36:58]through online learning.
[0:36:59]Some are better taught through in-person learning.
[0:37:01]Some are better taught through blended learning.
[0:37:03]And maybe that's the future.
[0:37:05]I don't know, you know, some people argue
[0:37:06]that AI is fundamentally different
[0:37:08]from all other revolutions like that
[0:37:10]that you're talking about.
[0:37:12]I personally have stopped contemplating about the future
[0:37:16]and, you know, kind of went back
[0:37:20]and remembered that in one of my MPH classes in Iran,
[0:37:24]one of my instructors used to say,
[0:37:26]used to basically talk about the kind of skills
[0:37:29]that we are going to need in the future centuries.
[0:37:31]And always on top of the list was uncertainty tolerance.
[0:37:35]And, you know, the fact that you and I should learn
[0:37:39]how to live in a world that is full of uncertainties
[0:37:41]as we expect our models to be tolerant
[0:37:44]and comfortable with uncertainty,
[0:37:46]I believe you and I should be
[0:37:48]much more comfortable than them.
[0:37:50]And this feeling comfortable with uncertainty
[0:37:54]technically means that, okay, here I am nowadays.
[0:37:56]This is what I am doing.
[0:37:58]I need to do it the best way I can.
[0:38:00]At the same time, I should be very, very ready
[0:38:02]to switch gears, to shift gears, to switch carrier,
[0:38:05]to switch studies, to switch what I am learning
[0:38:08]as soon as it is necessary, right?
[0:38:10]And, you know, to be honest,
[0:38:12]I watched a video on YouTube a few days ago.
[0:38:14]It was from a math, from a university math class in Iran,
[0:38:19]I believe in Sharif University.
[0:38:20]And instructor was just telling the students about,
[0:38:23]you know, the fact that we are just solving
[0:38:26]this very difficult mathematical equations on a blackboard.
[0:38:31]And you are questioning me that,
[0:38:32]where are we going to use these equations in real practice?
[0:38:35]You basically are just looking at the story
[0:38:38]from a wrong angle.
[0:38:40]This is not about you and us just solving the equations
[0:38:43]that we are going to use one day somewhere.
[0:38:46]This is about just getting used to solving difficult problems
[0:38:51]because if you just learn that skill,
[0:38:52]sometimes in your life, you are going to apply that skill
[0:38:55]to another problem that is now going to save your life,
[0:38:58]save your career, and maybe, you know,
[0:39:01]bring a lot of welfare to many other people.
[0:39:03]I think that's the most that we can do.
[0:39:05]You know, we should just stay up to date,
[0:39:07]stay ready to change,
[0:39:09]and be a little bit less frustrated about the future
[0:39:12]because regardless of whatever happens,
[0:39:14]we probably will find jobs, we'll find joy,
[0:39:17]we'll find family, we'll find things to do.
[0:39:19]And, you know, those who are really interesting
[0:39:21]about all these new technologies
[0:39:23]can still have a lot of different opportunities to grow
[0:39:26]and apply these technologies to many different things.
[0:39:28]That's my gain on it.
[0:39:30]Yeah, I totally agree.
[0:39:32]And yeah, so this was the first one that I had on the list.
[0:39:39]Quite an introduction, a long discussion for the beginning.
[0:39:43]Yeah, and to be honest, this topic was something
[0:39:47]that one of my friends who was watching our episodes
[0:39:50]asked me to once talk about.
[0:39:53]I mean, there are still spaces
[0:39:55]that we can dive deep into this question,
[0:39:57]but he was mainly interested in.
==== Ending of Part 4 ====